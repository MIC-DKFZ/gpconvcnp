{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP-ConvCNP Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will allow you to explore our proposed GP-ConvCNP as well as all the baselines. You will need to install the `neuralprocess` package contained within the ZIP file you received. For instructions on how to do that, please consult the `README.md`.\n",
    "\n",
    "Below, we will first construct data generators that produce functions like the ones used in the paper. We then load pretrained models and visualize predictions similar to the figures found in our paper. The last section offers an interactive example, where you can manually place context points. This is a good way to explore edge cases.\n",
    "\n",
    "**IMPORTANT: We experienced some weird behaviour going from %matplotlib inline (what the random examples use) to %matplotlib notebook (what the interactive example uses). If the interactive example doesn't work, rerun the cell or restart the kernel and skip the random example! If the widgets are not displayed and the notebook just prints Checkbox(...) etc., run the following command:**\n",
    "\n",
    "``jupyter nbextension enable --py widgetsnbextension``\n",
    "\n",
    "We will use the following abbreviations for the different function families:\n",
    "\n",
    "* `matern` for samples from a Gaussian Process with a Matern-5/2 kernel\n",
    "* `wp` for samples from a Gaussian Process with a weakly periodic kernel\n",
    "* `fourier` for randomly constructed Fourier series\n",
    "* `step` for step function samples\n",
    "* `lotka` for Lotka-Volterra based population dynamics\n",
    "* `temperature` for temperature time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from matplotlib import lines as mlines\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','serif':['Computer Modern Roman']})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "import neuralprocess\n",
    "from neuralprocess.data import (\n",
    "    GaussianProcessGenerator,\n",
    "    StepFunctionGenerator,\n",
    "    FourierSeriesGenerator,\n",
    "    gp,\n",
    "    LotkaVolterraGenerator,\n",
    "    TemperatureGenerator\n",
    ")\n",
    "from neuralprocess.model import pretrained\n",
    "from neuralprocess import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These generators are constructed to match what the models were trained on, except num_context and num_target, which are fixed. We choose num_context small enough to still allow for significant variation in the samples. Feel free to change parameters to see how well the methods handle those changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_kwargs = dict(\n",
    "    batch_size=1,\n",
    "    num_target=200,\n",
    "    output_noise=0.,\n",
    "    linspace=True\n",
    ")\n",
    "\n",
    "generators = {\n",
    "    \"matern\": GaussianProcessGenerator(\n",
    "        **base_kwargs,\n",
    "        x_range=(-3, 3),\n",
    "        num_context=15,\n",
    "        kernel_type=gp.Matern52Kernel,\n",
    "        kernel_kwargs=dict(lengthscale=0.5)\n",
    "    ),\n",
    "    \"wp\": GaussianProcessGenerator(\n",
    "        **base_kwargs,\n",
    "        x_range=(-3, 3),\n",
    "        num_context=20,\n",
    "        kernel_type=gp.WeaklyPeriodicKernel,\n",
    "        kernel_kwargs=dict()\n",
    "    ),\n",
    "    \"fourier\": FourierSeriesGenerator(\n",
    "        **base_kwargs,\n",
    "        x_range=(-3, 3),\n",
    "        num_context=20,\n",
    "        series_length=(10, 20),\n",
    "        amplitude=(-1, 1),\n",
    "        phase=(-1, 1),\n",
    "        bias=(-1, 1),\n",
    "        frequency_scale=1.0\n",
    "    ),\n",
    "    \"step\": StepFunctionGenerator(\n",
    "        **base_kwargs,\n",
    "        x_range=(-3, 3),\n",
    "        num_context=20,\n",
    "        y_range=(-3, 3),\n",
    "        number_of_steps=(3, 10),\n",
    "        min_step_width=0.1,\n",
    "        min_step_height=0.1\n",
    "    ),\n",
    "    \"lotka\": LotkaVolterraGenerator(\n",
    "        **base_kwargs,\n",
    "        num_context=20,\n",
    "        predator_init=(50, 100),\n",
    "        prey_init=(100, 150),\n",
    "        rate0=(0.005, 0.01),\n",
    "        rate1=(0.5, 0.8),\n",
    "        rate2=(0.5, 0.8),\n",
    "        rate3=(0.005, 0.01),\n",
    "        sequence_length=10000,\n",
    "        y_rescale=0.01,\n",
    "        x_rescale=0.1,\n",
    "        max_time=100.0,\n",
    "        max_population=500,\n",
    "        super_sample=1.5,\n",
    "    ),\n",
    "    \"temperature\": TemperatureGenerator(\n",
    "        **base_kwargs,\n",
    "        x_range=(0, 3),\n",
    "        num_context=50,\n",
    "        sequence_length=30*24\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models are very small (NP ~1.3MB, ANP ~2.1MB, ConvCNP & GP-ConvCNP ~207kB), so we can load them all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP_models = {}\n",
    "ANP_models = {}\n",
    "ConvCNP_models = {}\n",
    "GPConvCNP_models = {}\n",
    "\n",
    "for function_type in (\"matern\", \"wp\", \"step\", \"fourier\", \"lotka\", \"temperature\"):\n",
    "    NP_models[function_type] = pretrained.NeuralProcess(function_type).eval()\n",
    "    ANP_models[function_type] = pretrained.AttentiveNeuralProcess(function_type).eval()\n",
    "    ConvCNP_models[function_type] = pretrained.ConvCNP(function_type, use_gp=False).eval()\n",
    "    GPConvCNP_models[function_type] = pretrained.ConvCNP(function_type, use_gp=True).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Synthetic Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With the following cell you can generate random examples for the different function types, like the ones seen in the supplementary material of our submission (and similar to the ones in the main text). At the top of the cell are a number of configuration options:\n",
    "\n",
    "* `function_type` selects which function generator and models are used.\n",
    "* `num_samples` is the number of samples we draw from a method for a given example\n",
    "* `x_range` defines the x range. If you choose something wider than (-3, 3), you can see how well the methods generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "function_type = \"step\"  # you can change this to \"wp\" o\"step\"\n",
    "num_samples = 5  # number of samples for each example\n",
    "show_ticks = False  # You can use this to toggle axis ticks\n",
    "prediction_color = cm.tab10(0)\n",
    "sample_color = cm.tab10(3)\n",
    "y_range = (-5, 5)\n",
    "\n",
    "prediction_color = cm.tab10(0)\n",
    "sample_color = cm.tab10(3)\n",
    "y_labels = {\n",
    "    \"matern\": \"Matern-5/2 GP\",\n",
    "    \"wp\": \"Weakly Periodic GP\",\n",
    "    \"fourier\": \"Fourier Series\",\n",
    "    \"step\": \"Step Functions\"\n",
    "}\n",
    "\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(4, 4, figsize=(15, 10))\n",
    "\n",
    "for r, func in enumerate(y_labels.keys()):\n",
    "    \n",
    "    batch = next(generators[func])\n",
    "    \n",
    "    for m, model in enumerate((NP_models[func], ANP_models[func], ConvCNP_models[func], GPConvCNP_models[func])):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            ax[r, m].set_xlim(*generators[func].x_range)\n",
    "            ax[r, m].set_ylim(*y_range)\n",
    "            \n",
    "            prediction = model(batch[\"context_in\"], batch[\"context_out\"], batch[\"target_in\"], store_rep=True)\n",
    "            prediction = util.tensor_to_loc_scale(prediction, torch.distributions.Normal, axis=2)\n",
    "            \n",
    "            ax[r, m].fill_between(\n",
    "                batch[\"target_in\"][0, :, 0],\n",
    "                prediction.loc[0, :, 0] - prediction.scale[0, :, 0],\n",
    "                prediction.loc[0, :, 0] + prediction.scale[0, :, 0],\n",
    "                color=prediction_color,\n",
    "                alpha=0.3\n",
    "            )\n",
    "            ax[r, m].plot(\n",
    "                batch[\"target_in\"][0, :, 0],\n",
    "                batch[\"target_out\"][0, :, 0],\n",
    "                c=\"grey\",\n",
    "                linestyle=\":\"\n",
    "            )\n",
    "            if m != 2:\n",
    "                samples = model.sample(batch[\"target_in\"], num_samples)\n",
    "                samples = util.tensor_to_loc_scale(samples, torch.distributions.Normal, axis=3)\n",
    "                ax[r, m].plot(batch[\"target_in\"][0, :], samples.loc[:, 0, :, 0].T, c=sample_color, alpha=0.3)\n",
    "            ax[r, m].plot(batch[\"target_in\"][0, :, 0], prediction.loc[0, :, 0], c=prediction_color)\n",
    "            ax[r, m].plot(\n",
    "                batch[\"context_in\"][0, :, 0],\n",
    "                batch[\"context_out\"][0, :, 0],\n",
    "                c=\"black\",\n",
    "                marker=\"o\",\n",
    "                ms=3,\n",
    "                linewidth=0\n",
    "            )\n",
    "                \n",
    "            if not show_ticks:\n",
    "                ax[r, m].set_xticks([])\n",
    "                ax[r, m].set_yticks([])\n",
    "                \n",
    "    ax[r, 0].set_ylabel(y_labels[func])\n",
    "            \n",
    "ax[0, 0].set_title(\"NP\")\n",
    "ax[0, 1].set_title(\"ANP\")\n",
    "ax[0, 2].set_title(r\"\\textsc{ConvCNP}\")\n",
    "ax[0, 3].set_title(r\"\\textsc{GP-ConvCNP}\")\n",
    "        \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Temperature Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Produce figures similar to figure 2 from our submission. There are some configuration options at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "convcnp = True  # if True, will show ConvCNP and GP-ConvCNP, otherwise NP and ANP\n",
    "prediction_color = cm.tab10(0)\n",
    "rows = 1  # each row is one example\n",
    "\n",
    "fig, ax = plt.subplots(rows, 4, figsize=(15, 3*rows), sharey=True)\n",
    "if ax.ndim == 1:\n",
    "    ax = ax[None, :]\n",
    "\n",
    "gen = generators[\"temperature\"]\n",
    "x_norm = gen.sequence_length / (gen.x_range[1] - gen.x_range[0]) / 24  # days\n",
    "        \n",
    "for r in range(rows):\n",
    "    \n",
    "    if convcnp:\n",
    "        models = (ConvCNP_models[\"temperature\"], GPConvCNP_models[\"temperature\"])\n",
    "    else:\n",
    "        models = (NP_models[\"temperature\"], ANP_models[\"temperature\"])\n",
    "        \n",
    "    batch = next(gen)\n",
    "    city = batch[\"cities\"][0]\n",
    "    \n",
    "    # INTERPOLATION\n",
    "    \n",
    "    for m, model in enumerate(models):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            prediction = model(batch[\"context_in\"], batch[\"context_out\"], batch[\"target_in\"], store_rep=True)\n",
    "            prediction = util.tensor_to_loc_scale(prediction, torch.distributions.Normal, axis=2)\n",
    "            prediction.loc = prediction.loc * gen.std_temp[city] + gen.mean_temp[city]\n",
    "            prediction.scale = prediction.scale * gen.std_temp[city]\n",
    "            \n",
    "            ax[r, m].fill_between(\n",
    "                batch[\"target_in\"][0, :, 0] * x_norm,\n",
    "                prediction.loc[0, :, 0] - prediction.scale[0, :, 0],\n",
    "                prediction.loc[0, :, 0] + prediction.scale[0, :, 0],\n",
    "                color=prediction_color,\n",
    "                alpha=0.3\n",
    "            )\n",
    "            ax[r, m].plot(\n",
    "                batch[\"x\"][0, :, 0] * x_norm,\n",
    "                batch[\"y\"][0, :, 0] * gen.std_temp[city] + gen.mean_temp[city],\n",
    "                c=\"grey\",\n",
    "                linestyle=\":\"\n",
    "            )\n",
    "            ax[r, m].plot(\n",
    "                batch[\"target_in\"][0, :, 0] * x_norm,\n",
    "                prediction.loc[0, :, 0],\n",
    "                c=prediction_color\n",
    "            )\n",
    "            ax[r, m].plot(\n",
    "                batch[\"context_in\"][0, :, 0] * x_norm,\n",
    "                batch[\"context_out\"][0, :, 0] * gen.std_temp[city] + gen.mean_temp[city],\n",
    "                c=\"black\",\n",
    "                marker=\"o\",\n",
    "                ms=3,\n",
    "                linewidth=0\n",
    "            )\n",
    "            \n",
    "    # EXTRAPOLATION\n",
    "            \n",
    "    x = batch[\"x\"]\n",
    "    y = batch[\"y\"]\n",
    "\n",
    "    x_context = batch[\"x\"][:, :x.shape[1] // 2]\n",
    "    y_context = batch[\"y\"][:, :y.shape[1] // 2]\n",
    "\n",
    "    num_context = batch[\"context_in\"].shape[1] // 2\n",
    "    context_indices = np.random.choice(np.arange(x_context.shape[1]), num_context, replace=False)\n",
    "    context_indices.sort()\n",
    "\n",
    "    batch[\"context_in\"] = torch.from_numpy(x_context[:, context_indices]).float()\n",
    "    batch[\"context_out\"] = torch.from_numpy(y_context[:, context_indices]).float()\n",
    "    batch[\"target_in\"] = torch.from_numpy(batch[\"x\"][:, x.shape[1] // 2:]).float()\n",
    "    batch[\"target_out\"] = torch.from_numpy(batch[\"y\"][:, x.shape[1] // 2:]).float()\n",
    "    \n",
    "    for m, model in enumerate(models):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            prediction = model(batch[\"context_in\"], batch[\"context_out\"], batch[\"target_in\"], store_rep=True)\n",
    "            prediction = util.tensor_to_loc_scale(prediction, torch.distributions.Normal, axis=2)\n",
    "            prediction.loc = prediction.loc * gen.std_temp[city] + gen.mean_temp[city]\n",
    "            prediction.scale = prediction.scale * gen.std_temp[city]\n",
    "            \n",
    "            ax[r, m + 2].fill_between(\n",
    "                batch[\"target_in\"][0, :, 0] * x_norm,\n",
    "                prediction.loc[0, :, 0] - prediction.scale[0, :, 0],\n",
    "                prediction.loc[0, :, 0] + prediction.scale[0, :, 0],\n",
    "                color=prediction_color,\n",
    "                alpha=0.3\n",
    "            )\n",
    "            ax[r, m + 2].plot(\n",
    "                batch[\"x\"][0, :, 0] * x_norm,\n",
    "                batch[\"y\"][0, :, 0] * gen.std_temp[city] + gen.mean_temp[city],\n",
    "                c=\"grey\",\n",
    "                linestyle=\":\"\n",
    "            )\n",
    "            ax[r, m + 2].plot(\n",
    "                batch[\"target_in\"][0, :, 0] * x_norm,\n",
    "                prediction.loc[0, :, 0],\n",
    "                c=prediction_color\n",
    "            )\n",
    "            ax[r, m + 2].plot(\n",
    "                batch[\"context_in\"][0, :, 0] * x_norm,\n",
    "                batch[\"context_out\"][0, :, 0] * gen.std_temp[city] + gen.mean_temp[city],\n",
    "                c=\"black\",\n",
    "                marker=\"o\",\n",
    "                ms=3,\n",
    "                linewidth=0\n",
    "            )\n",
    "            \n",
    "            ax[r, m].set_xlim(0, 3 * x_norm)\n",
    "            ax[r, m + 2].set_xlim(0, 3 * x_norm)\n",
    "            \n",
    "    ax[r, 0].set_ylabel(\"Temperature [K]\")\n",
    "            \n",
    "if convcnp:\n",
    "    ax[0, 0].set_title(r\"\\textsc{ConvCNP}\")\n",
    "    ax[0, 2].set_title(r\"\\textsc{ConvCNP}\")\n",
    "    ax[0, 1].set_title(r\"\\textsc{GP-ConvCNP}\")\n",
    "    ax[0, 3].set_title(r\"\\textsc{GP-ConvCNP}\")\n",
    "else:\n",
    "    ax[0, 0].set_title(\"NP\")\n",
    "    ax[0, 2].set_title(\"NP\")\n",
    "    ax[0, 1].set_title(\"ANP\")\n",
    "    ax[0, 3].set_title(\"ANP\")\n",
    "for i in range(4):\n",
    "    ax[-1, i].set_xlabel(\"Time [days]\")\n",
    "        \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Population Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Produce figures similar to figure 3 from our submission. There are some configuration options at the top. The real data has a different range than the simulated data, so we normalize the real data to have the same mean population and mean duration as the simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "convcnp = False  # if True, will show ConvCNP and GP-ConvCNP, otherwise NP and ANP\n",
    "predator_color = cm.tab10(0)\n",
    "prey_color = cm.tab10(1)\n",
    "markersize = 6\n",
    "target_marker = \"x\"\n",
    "\n",
    "gen = generators[\"lotka\"]\n",
    "gen.num_target = 100\n",
    "if convcnp:\n",
    "    models = (ConvCNP_models[\"lotka\"], GPConvCNP_models[\"lotka\"])\n",
    "else:\n",
    "    models = (NP_models[\"lotka\"], ANP_models[\"lotka\"])\n",
    "\n",
    "# simulated data first\n",
    "data_sim = next(gen)\n",
    "target_in_sim = torch.linspace(data_sim[\"target_in\"].min(), data_sim[\"target_in\"].max(), 500)[None, :, None]\n",
    "predictions_loc_sim = []\n",
    "predictions_scale_sim = []\n",
    "samples_sim = []\n",
    "for model in models:\n",
    "    with torch.no_grad():\n",
    "        prediction = model(data_sim[\"context_in\"], data_sim[\"context_out\"], target_in_sim)\n",
    "        prediction = util.tensor_to_loc_scale(prediction, torch.distributions.Normal, axis=2)\n",
    "        predictions_loc_sim.append(prediction.loc)\n",
    "        predictions_scale_sim.append(prediction.scale)\n",
    "\n",
    "# now real data\n",
    "data_real = neuralprocess.data.get_lynx_hare_data()\n",
    "norm_population = 0.032  # so that simulated and real data have the same mean populations\n",
    "norm_years = 4.337  # so that simulated and real data have the same mean duration\n",
    "test_interval_start = 66\n",
    "test_interval_length = 18\n",
    "\n",
    "min_year = data_real.values[0, 0]\n",
    "max_year = data_real.values[-1, 0]\n",
    "years = norm_years * (data_real.values[:, 0:1] - min_year) / (max_year - min_year)\n",
    "population = norm_population * data_real.values[:, 1:]\n",
    "test_interval = (test_interval_start, test_interval_start + test_interval_length + 1)\n",
    "                        \n",
    "context_in_real = torch.from_numpy(\n",
    "    np.concatenate((\n",
    "        years[:test_interval[0], :],\n",
    "        years[test_interval[1]:, :]\n",
    "    ), 0)[None, ...]\n",
    ").float()\n",
    "context_out_real = torch.from_numpy(\n",
    "    np.concatenate((\n",
    "        population[:test_interval[0], :],\n",
    "        population[test_interval[1]:, :]\n",
    "    ), 0)[None, ...]\n",
    ").float()\n",
    "target_in_real = torch.linspace(0, norm_years, 500)[None, :, None]\n",
    "\n",
    "predictions_loc_real = []\n",
    "predictions_scale_real = []\n",
    "samples_real = []\n",
    "for model in models:\n",
    "    with torch.no_grad():\n",
    "        prediction = model(context_in_real, context_out_real, target_in_real)\n",
    "        prediction = util.tensor_to_loc_scale(prediction, torch.distributions.Normal, axis=2)\n",
    "        predictions_loc_real.append(prediction.loc)\n",
    "        predictions_scale_real.append(prediction.scale)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 6))\n",
    "\n",
    "for m, model in enumerate(models):\n",
    "    \n",
    "    ax[0, m].set_xlim(0, data_sim[\"target_in\"].max().item() / gen.x_rescale)\n",
    "    ax[0, m].set_ylim(-10, 1.2 * data_sim[\"target_out\"].max() / gen.y_rescale)\n",
    "    ax[1, m].set_xlim(min_year, max_year)\n",
    "    ax[1, m].set_ylim(-10, 150)\n",
    "    if m > 0:\n",
    "        ax[0, m].set_yticks([])\n",
    "        ax[1, m].set_yticks([])\n",
    "    ax[1, m].set_xlabel(\"Time [years]\")\n",
    "    if m == 0:\n",
    "        ax[0, 0].set_ylabel(\"Population [thousands]\")\n",
    "        ax[1, 0].set_ylabel(\"Population [thousands]\")\n",
    "\n",
    "    # simulated\n",
    "    ax[0, m].fill_between(\n",
    "        target_in_sim[0, :, 0] / gen.x_rescale,\n",
    "        (predictions_loc_sim[m][0, :, 0] - predictions_scale_sim[m][0, :, 0]) / gen.y_rescale,\n",
    "        (predictions_loc_sim[m][0, :, 0] + predictions_scale_sim[m][0, :, 0]) / gen.y_rescale,\n",
    "        color=predator_color,\n",
    "        alpha=0.2\n",
    "    )\n",
    "    ax[0, m].fill_between(\n",
    "        target_in_sim[0, :, 0] / gen.x_rescale,\n",
    "        (predictions_loc_sim[m][0, :, 1] - predictions_scale_sim[m][0, :, 1]) / gen.y_rescale,\n",
    "        (predictions_loc_sim[m][0, :, 1] + predictions_scale_sim[m][0, :, 1]) / gen.y_rescale,\n",
    "        color=prey_color,\n",
    "        alpha=0.2\n",
    "    )\n",
    "    ax[0, m].plot(\n",
    "        target_in_sim[0, :, 0] / gen.x_rescale,\n",
    "        predictions_loc_sim[m][0, :, 0] / gen.y_rescale,\n",
    "        c=predator_color\n",
    "    )\n",
    "    ax[0, m].plot(\n",
    "        target_in_sim[0, :, 0] / gen.x_rescale,\n",
    "        predictions_loc_sim[m][0, :, 1] / gen.y_rescale,\n",
    "        c=prey_color\n",
    "    )\n",
    "    ax[0, m].plot(\n",
    "        data_sim[\"context_in\"][0] / gen.x_rescale,\n",
    "        data_sim[\"context_out\"][0, :, 0:1] / gen.y_rescale,\n",
    "        linewidth=0,\n",
    "        c=predator_color,\n",
    "        marker=\"o\",\n",
    "        ms=markersize\n",
    "    )\n",
    "    ax[0, m].plot(\n",
    "        data_sim[\"context_in\"][0] / gen.x_rescale,\n",
    "        data_sim[\"context_out\"][0, :, 1:2] / gen.y_rescale,\n",
    "        c=prey_color,\n",
    "        linewidth=0,\n",
    "        marker=\"o\",\n",
    "        ms=markersize\n",
    "    )\n",
    "    ax[0, m].plot(\n",
    "        data_sim[\"target_in\"][0] / gen.x_rescale,\n",
    "        data_sim[\"target_out\"][0, :, 0:1] / gen.y_rescale,\n",
    "        linewidth=0,\n",
    "        c=predator_color,\n",
    "        marker=target_marker,\n",
    "        fillstyle=\"none\",\n",
    "        ms=markersize\n",
    "    )\n",
    "    ax[0, m].plot(\n",
    "        data_sim[\"target_in\"][0] / gen.x_rescale,\n",
    "        data_sim[\"target_out\"][0, :, 1:2] / gen.y_rescale,\n",
    "        c=prey_color,\n",
    "        linewidth=0,\n",
    "        marker=target_marker,\n",
    "        fillstyle=\"none\",\n",
    "        ms=markersize\n",
    "    )\n",
    "    \n",
    "    # real\n",
    "    ax[1, m].fill_between(\n",
    "        target_in_real[0, :, 0] * (max_year - min_year) / norm_years + min_year,\n",
    "        (predictions_loc_real[m][0, :, 0] - predictions_scale_real[m][0, :, 0]) / norm_population,\n",
    "        (predictions_loc_real[m][0, :, 0] + predictions_scale_real[m][0, :, 0]) / norm_population,\n",
    "        color=predator_color,\n",
    "        alpha=0.2\n",
    "    )\n",
    "    ax[1, m].fill_between(\n",
    "        target_in_real[0, :, 0] * (max_year - min_year) / norm_years + min_year,\n",
    "        (predictions_loc_real[m][0, :, 1] - predictions_scale_real[m][0, :, 1]) / norm_population,\n",
    "        (predictions_loc_real[m][0, :, 1] + predictions_scale_real[m][0, :, 1]) / norm_population,\n",
    "        color=prey_color,\n",
    "        alpha=0.2\n",
    "    )\n",
    "    ax[1, m].plot(\n",
    "        target_in_real[0, :, 0] * (max_year - min_year) / norm_years + min_year,\n",
    "        predictions_loc_real[m][0, :, 0] / norm_population,\n",
    "        c=predator_color\n",
    "    )\n",
    "    ax[1, m].plot(\n",
    "        target_in_real[0, :, 0] * (max_year - min_year) / norm_years + min_year,\n",
    "        predictions_loc_real[m][0, :, 1] / norm_population,\n",
    "        c=prey_color\n",
    "    )\n",
    "    ax[1, m].plot(\n",
    "        context_in_real[0] * (max_year - min_year) / norm_years + min_year,\n",
    "        context_out_real[0, :, 0:1] / norm_population,\n",
    "        linewidth=0,\n",
    "        c=predator_color,\n",
    "        marker=\"o\",\n",
    "        ms=markersize\n",
    "    )\n",
    "    ax[1, m].plot(\n",
    "        context_in_real[0] * (max_year - min_year) / norm_years + min_year,\n",
    "        context_out_real[0, :, 1:2] / norm_population,\n",
    "        c=prey_color,\n",
    "        linewidth=0,\n",
    "        marker=\"o\",\n",
    "        ms=markersize\n",
    "    )\n",
    "    ax[1, m].plot(\n",
    "        data_real.values[test_interval[0]:test_interval[1], 0],\n",
    "        data_real.values[test_interval[0]:test_interval[1], 1],\n",
    "        linewidth=0,\n",
    "        c=predator_color,\n",
    "        marker=target_marker,\n",
    "        fillstyle=\"none\",\n",
    "        ms=markersize\n",
    "    )\n",
    "    ax[1, m].plot(\n",
    "        data_real.values[test_interval[0]:test_interval[1], 0],\n",
    "        data_real.values[test_interval[0]:test_interval[1], 2],\n",
    "        linewidth=0,\n",
    "        c=prey_color,\n",
    "        marker=target_marker,\n",
    "        fillstyle=\"none\",\n",
    "        ms=markersize\n",
    "    )\n",
    "\n",
    "context_handle_predator = mlines.Line2D([], [], c=predator_color, linewidth=0, marker=\"o\", label=\"Context Predator\")\n",
    "context_handle_prey = mlines.Line2D([], [], c=prey_color, linewidth=0, marker=\"o\", label=\"Context Prey\")\n",
    "target_handle_predator = mlines.Line2D([], [], c=predator_color, linewidth=0, marker=target_marker, label=\"Target Predator\")\n",
    "target_handle_prey = mlines.Line2D([], [], c=prey_color, linewidth=0, marker=target_marker, label=\"Target Prey\")\n",
    "ax[0, -1].legend(frameon=False, handles=[context_handle_predator, context_handle_prey, target_handle_predator, target_handle_prey])\n",
    "\n",
    "if convcnp:\n",
    "    ax[0, 0].set_title(r\"\\textsc{ConvCNP}\")\n",
    "    ax[0, 1].set_title(r\"\\textsc{GP-ConvCNP}\")\n",
    "else:\n",
    "    ax[0, 0].set_title(\"NP\")\n",
    "    ax[0, 1].set_title(\"ANP\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following interactive example gives you the opportunity to manually place context points and see how the different methods behave. There are checkboxes to activate each method individually as well as one to toggle display of the predictive uncertainty. A dropdown menu gives you the option to select on what kinds of functions the models should have been trained. This example is especially useful to explore corner cases and failure modes. It's easy to place context points in a way that makes them unlikely to come from a true sample, and the predictions will reflect that. The training range will be indicated by vertical lines, keep in mind that NP and ANP perform very poorly when points are placed outside of that range.\n",
    "\n",
    "The top panel shows mean predictions and the bottom panel shows samples. The panels will be empty in the beginning, and you need to manually add points. You can remove points by clicking on them again. Note that only the top panel is interactive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "x_range = (-6, 6)\n",
    "num_samples = 5\n",
    "\n",
    "# Set up selectors\n",
    "gpconvcnp_box = widgets.Checkbox(value=True, description=\"GP-ConvCNP\")\n",
    "convcnp_box = widgets.Checkbox(value=False, description=\"ConvCNP\")\n",
    "anp_box = widgets.Checkbox(value=False, description=\"ANP\")\n",
    "np_box = widgets.Checkbox(value=False, description=\"NP\")\n",
    "sigma_box = widgets.Checkbox(value=True, description=\"Show Sigma\")\n",
    "function_selector = widgets.Dropdown(\n",
    "    options=[\"matern\", \"wp\", \"fourier\", \"step\"],\n",
    "    value=\"matern\",\n",
    "    description=\"Type\"\n",
    ")\n",
    "\n",
    "display(gpconvcnp_box, convcnp_box, anp_box, np_box, sigma_box, function_selector)\n",
    "\n",
    "class FigureBuilder:\n",
    "    \n",
    "    def __init__(self, ax):\n",
    "        \n",
    "        self.ax = ax\n",
    "\n",
    "        self.sigma_handle_np = ax[0].fill_between([], [], [], color=cm.tab10(3), alpha=0.3)\n",
    "        self.prediction_handle_np = ax[0].plot([], [], color=cm.tab10(3), linewidth=1)[0]\n",
    "        self.sigma_handle_anp = ax[0].fill_between([], [], [], color=cm.tab10(2), alpha=0.3)\n",
    "        self.prediction_handle_anp = ax[0].plot([], [], color=cm.tab10(2), linewidth=1)[0]\n",
    "        self.sigma_handle_convcnp = ax[0].fill_between([], [], [], color=cm.tab10(1), alpha=0.3)\n",
    "        self.prediction_handle_convcnp = ax[0].plot([], [], color=cm.tab10(1), linewidth=1)[0]\n",
    "        self.sigma_handle_gpconvcnp = ax[0].fill_between([], [], [], color=cm.tab10(0), alpha=0.3)\n",
    "        self.prediction_handle_gpconvcnp = ax[0].plot([], [], color=cm.tab10(0), linewidth=1)[0]\n",
    "        \n",
    "        self.context_handle_0 = ax[0].plot([], [], color=\"black\", linewidth=0, marker=\"o\", ms=6)[0]\n",
    "        self.context_points = []\n",
    "        self.cid = self.context_handle_0.figure.canvas.mpl_connect('button_press_event', self)\n",
    "        \n",
    "    def draw(self, *args, **kwargs):\n",
    "        \n",
    "        self.sigma_handle_np.get_paths().clear()\n",
    "        self.sigma_handle_anp.get_paths().clear()\n",
    "        self.sigma_handle_convcnp.get_paths().clear()\n",
    "        self.sigma_handle_gpconvcnp.get_paths().clear()\n",
    "        \n",
    "        if len(self.context_points) > 0:\n",
    "            \n",
    "            # context points\n",
    "            arr = np.array(self.context_points)\n",
    "            self.context_handle_0.set_data(arr[:, 0], arr[:, 1])\n",
    "            \n",
    "            # prediction\n",
    "            context_in = torch.from_numpy(arr[:, 0]).float().reshape(1, -1, 1)\n",
    "            context_out = torch.from_numpy(arr[:, 1]).float().reshape(1, -1, 1)\n",
    "            target_in = torch.linspace(*x_range, 500).reshape(1, -1, 1)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                func = function_selector.value\n",
    "                \n",
    "                if gpconvcnp_box.value:\n",
    "                    prediction = GPConvCNP_models[func](context_in, context_out, target_in, store_rep=True)\n",
    "                    prediction = util.tensor_to_loc_scale(prediction, torch.distributions.Normal, axis=2)    \n",
    "                    self.prediction_handle_gpconvcnp.set_data(target_in[0, :, 0], prediction.loc[0, :, 0])\n",
    "                    if sigma_box.value:\n",
    "                        self.sigma_handle_gpconvcnp = self.ax[0].fill_between(\n",
    "                            target_in[0, :, 0],\n",
    "                            prediction.loc[0, :, 0] - prediction.scale[0, :, 0],\n",
    "                            prediction.loc[0, :, 0] + prediction.scale[0, :, 0],\n",
    "                            color=cm.tab10(0),\n",
    "                            alpha=0.3\n",
    "                        )\n",
    "                else:\n",
    "                    self.prediction_handle_gpconvcnp.set_data([], [])\n",
    "                    \n",
    "                if convcnp_box.value:\n",
    "                    prediction = ConvCNP_models[func](context_in, context_out, target_in)\n",
    "                    prediction = util.tensor_to_loc_scale(prediction, torch.distributions.Normal, axis=2)    \n",
    "                    self.prediction_handle_convcnp.set_data(target_in[0, :, 0], prediction.loc[0, :, 0])\n",
    "                    if sigma_box.value:\n",
    "                        self.sigma_handle_convcnp = self.ax[0].fill_between(\n",
    "                            target_in[0, :, 0],\n",
    "                            prediction.loc[0, :, 0] - prediction.scale[0, :, 0],\n",
    "                            prediction.loc[0, :, 0] + prediction.scale[0, :, 0],\n",
    "                            color=cm.tab10(1),\n",
    "                            alpha=0.3\n",
    "                        )\n",
    "                else:\n",
    "                    self.prediction_handle_convcnp.set_data([], [])\n",
    "                    \n",
    "                if anp_box.value:\n",
    "                    prediction = ANP_models[func](context_in, context_out, target_in, store_rep=True)\n",
    "                    prediction = util.tensor_to_loc_scale(prediction, torch.distributions.Normal, axis=2)    \n",
    "                    self.prediction_handle_anp.set_data(target_in[0, :, 0], prediction.loc[0, :, 0])\n",
    "                    if sigma_box.value:\n",
    "                        self.sigma_handle_anp = self.ax[0].fill_between(\n",
    "                            target_in[0, :, 0],\n",
    "                            prediction.loc[0, :, 0] - prediction.scale[0, :, 0],\n",
    "                            prediction.loc[0, :, 0] + prediction.scale[0, :, 0],\n",
    "                            color=cm.tab10(2),\n",
    "                            alpha=0.3\n",
    "                        )\n",
    "                else:\n",
    "                    self.prediction_handle_anp.set_data([], [])\n",
    "\n",
    "                if np_box.value:\n",
    "                    prediction = NP_models[func](context_in, context_out, target_in, store_rep=True)\n",
    "                    prediction = util.tensor_to_loc_scale(prediction, torch.distributions.Normal, axis=2)    \n",
    "                    self.prediction_handle_np.set_data(target_in[0, :, 0], prediction.loc[0, :, 0])\n",
    "                    if sigma_box.value:\n",
    "                        self.sigma_handle_np = self.ax[0].fill_between(\n",
    "                            target_in[0, :, 0],\n",
    "                            prediction.loc[0, :, 0] - prediction.scale[0, :, 0],\n",
    "                            prediction.loc[0, :, 0] + prediction.scale[0, :, 0],\n",
    "                            color=cm.tab10(3),\n",
    "                            alpha=0.3\n",
    "                        )\n",
    "                else:\n",
    "                    self.prediction_handle_np.set_data([], [])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.context_handle_0.set_data([], [])\n",
    "            self.prediction_handle_np.set_data([], [])\n",
    "            self.prediction_handle_anp.set_data([], [])\n",
    "            self.prediction_handle_convcnp.set_data([], [])\n",
    "            self.prediction_handle_gpconvcnp.set_data([], [])\n",
    "            \n",
    "        self.context_handle_0.figure.canvas.draw()\n",
    "\n",
    "    def __call__(self, event):\n",
    "        \n",
    "        if event.inaxes!=self.context_handle_0.axes:\n",
    "            return\n",
    "        \n",
    "        x = event.xdata\n",
    "        y = event.ydata\n",
    "        \n",
    "        for p, point in enumerate(self.context_points):\n",
    "            dist = np.sqrt((point[0] - x)**2 + (point[1] - y)**2)\n",
    "            if dist < 0.1:\n",
    "                del self.context_points[p]\n",
    "                break\n",
    "        else:\n",
    "            self.context_points.append((x, y))\n",
    "\n",
    "        self.draw()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "ax = [ax, ]\n",
    "\n",
    "ax[0].set_xlim(*x_range)\n",
    "ax[0].set_ylim(-3, 3)\n",
    "if x_range[0] < -3:\n",
    "    ax[0].axvline(-3, c=\"black\", alpha=0.3)\n",
    "if x_range[1] > 3:\n",
    "    ax[0].axvline(3, c=\"black\", alpha=0.3)\n",
    "\n",
    "figurebuilder = FigureBuilder(ax)\n",
    "\n",
    "# Register widgets\n",
    "for widget in (gpconvcnp_box, convcnp_box, anp_box, np_box, sigma_box, function_selector):\n",
    "    widget.observe(figurebuilder.draw)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
